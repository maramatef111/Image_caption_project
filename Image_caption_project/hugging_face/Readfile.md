# Image Captioning with Vision Encoder-Decoder Model
This repository contains code for generating captions for images using the Vision Encoder-Decoder model from Hugging Face's transformers library.

## Overview
The provided code defines a function predict_caption(img_paths) that takes a list of image file paths as input and generates captions for each image
using the pre-trained Vision Encoder-Decoder model.
